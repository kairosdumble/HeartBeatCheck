{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO6HrTUem9tLEnfLn+jYZo/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kairosdumble/HeartBeatCheck/blob/main/ECG_AI_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install numpy\n",
        "!pip install scikit-learn"
      ],
      "metadata": {
        "id": "IPmwIuDfaoVb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "233d34bf-9a65-4c62-8c99-5ec8e925d603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install wfdb numpy pandas"
      ],
      "metadata": {
        "id": "ENzYnTymUo7E",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39e4c299-b151-4768-f283-4f2f62f40c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.2 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import wfdb, numpy as np, pandas as pd\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path\n",
        "from scipy.signal import butter, lfilter\n",
        "\n",
        "wfdb.dl_database('mitdb', dl_dir='mitdb')\n",
        "BASE = Path('mitdb')"
      ],
      "metadata": {
        "id": "W25WXruDsoZ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c24b105e-9590-4156-ac24-b30dfd981461",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating record list for: 100\n",
            "Generating record list for: 101\n",
            "Generating record list for: 102\n",
            "Generating record list for: 103\n",
            "Generating record list for: 104\n",
            "Generating record list for: 105\n",
            "Generating record list for: 106\n",
            "Generating record list for: 107\n",
            "Generating record list for: 108\n",
            "Generating record list for: 109\n",
            "Generating record list for: 111\n",
            "Generating record list for: 112\n",
            "Generating record list for: 113\n",
            "Generating record list for: 114\n",
            "Generating record list for: 115\n",
            "Generating record list for: 116\n",
            "Generating record list for: 117\n",
            "Generating record list for: 118\n",
            "Generating record list for: 119\n",
            "Generating record list for: 121\n",
            "Generating record list for: 122\n",
            "Generating record list for: 123\n",
            "Generating record list for: 124\n",
            "Generating record list for: 200\n",
            "Generating record list for: 201\n",
            "Generating record list for: 202\n",
            "Generating record list for: 203\n",
            "Generating record list for: 205\n",
            "Generating record list for: 207\n",
            "Generating record list for: 208\n",
            "Generating record list for: 209\n",
            "Generating record list for: 210\n",
            "Generating record list for: 212\n",
            "Generating record list for: 213\n",
            "Generating record list for: 214\n",
            "Generating record list for: 215\n",
            "Generating record list for: 217\n",
            "Generating record list for: 219\n",
            "Generating record list for: 220\n",
            "Generating record list for: 221\n",
            "Generating record list for: 222\n",
            "Generating record list for: 223\n",
            "Generating record list for: 228\n",
            "Generating record list for: 230\n",
            "Generating record list for: 231\n",
            "Generating record list for: 232\n",
            "Generating record list for: 233\n",
            "Generating record list for: 234\n",
            "Generating list of all files for: 100\n",
            "Generating list of all files for: 101\n",
            "Generating list of all files for: 102\n",
            "Generating list of all files for: 103\n",
            "Generating list of all files for: 104\n",
            "Generating list of all files for: 105\n",
            "Generating list of all files for: 106\n",
            "Generating list of all files for: 107\n",
            "Generating list of all files for: 108\n",
            "Generating list of all files for: 109\n",
            "Generating list of all files for: 111\n",
            "Generating list of all files for: 112\n",
            "Generating list of all files for: 113\n",
            "Generating list of all files for: 114\n",
            "Generating list of all files for: 115\n",
            "Generating list of all files for: 116\n",
            "Generating list of all files for: 117\n",
            "Generating list of all files for: 118\n",
            "Generating list of all files for: 119\n",
            "Generating list of all files for: 121\n",
            "Generating list of all files for: 122\n",
            "Generating list of all files for: 123\n",
            "Generating list of all files for: 124\n",
            "Generating list of all files for: 200\n",
            "Generating list of all files for: 201\n",
            "Generating list of all files for: 202\n",
            "Generating list of all files for: 203\n",
            "Generating list of all files for: 205\n",
            "Generating list of all files for: 207\n",
            "Generating list of all files for: 208\n",
            "Generating list of all files for: 209\n",
            "Generating list of all files for: 210\n",
            "Generating list of all files for: 212\n",
            "Generating list of all files for: 213\n",
            "Generating list of all files for: 214\n",
            "Generating list of all files for: 215\n",
            "Generating list of all files for: 217\n",
            "Generating list of all files for: 219\n",
            "Generating list of all files for: 220\n",
            "Generating list of all files for: 221\n",
            "Generating list of all files for: 222\n",
            "Generating list of all files for: 223\n",
            "Generating list of all files for: 228\n",
            "Generating list of all files for: 230\n",
            "Generating list of all files for: 231\n",
            "Generating list of all files for: 232\n",
            "Generating list of all files for: 233\n",
            "Generating list of all files for: 234\n",
            "Created local base download directory: mitdb\n",
            "Downloading files...\n",
            "Finished downloading files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CUTOFF = 0.5  # Hz\n",
        "FS = 360\n",
        "SAMPLING_RATE =360\n",
        "WINDOW_SIZE = 361"
      ],
      "metadata": {
        "id": "s5ud4ydrTe3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.1 학습용/ 검증용/ 평가용데이터 분리"
      ],
      "metadata": {
        "id": "bfyPaGgASwFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DS1/DS2(환자 분리)\n",
        "DS1 = [101,106,108,109,112,114,115,116,118,119,122,124,201,203,205,207,208,209,215,220,223,230]\n",
        "DS2 = [100,103,105,111,113,117,121,123,200,202,210,212,213,214,219,221,222,228,231,232,233,234]\n",
        "\n",
        "#숫자 리스트를 문자열 리스트로 변환\n",
        "DS1 = list(map(str, DS1))\n",
        "DS2 = list(map(str, DS2))\n",
        "\n",
        "VAL_N = 4 # DS1의 마지막 4개를 검증용으로 사용\n",
        "train_recs = DS1[:-VAL_N] # 학습용 데이터 (모델이 가중치를 배우는 데이터)\n",
        "val_recs   = DS1[-VAL_N:] # 검증용 데이터(학습 중 과적합 여부 확인 / 하이퍼파라미터 튜닝)\n",
        "test_recs  = DS2          # 평가용 데이터(모델이 전혀 보지 못한 환자 데이터로)\n",
        "\n",
        "print('Train:', train_recs)\n",
        "print('Val  :', val_recs)\n",
        "print('Test :', test_recs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nuEeH8Co7_G",
        "outputId": "93f13e84-58d5-4412-b16f-ef6bd6baf755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: ['101', '106', '108', '109', '112', '114', '115', '116', '118', '119', '122', '124', '201', '203', '205', '207', '208', '209']\n",
            "Val  : ['215', '220', '223', '230']\n",
            "Test : ['100', '103', '105', '111', '113', '117', '121', '123', '200', '202', '210', '212', '213', '214', '219', '221', '222', '228', '231', '232', '233', '234']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_recs))\n",
        "print(len(val_recs))\n",
        "print(len(test_recs))"
      ],
      "metadata": {
        "id": "Bvuk0DPy7u4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.2 AAMI 기준을 이진 분류(정상 vs 부정맥)"
      ],
      "metadata": {
        "id": "HxXhf3fPS5IK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#AAMI 매핑 & 제외 규칙\n",
        "AAMI_MAP = {\n",
        "    'N': set(['N','L','R','e','j']),\n",
        "    'S': set(['A','a','J','S']),\n",
        "    'V': set(['V','E']),\n",
        "    'F': set(['F']),\n",
        "    'Q': set(['Q'])\n",
        "}\n",
        "EXCLUDE = set(['/','f','Q','|','x','~','!','[',']','+', '\"'])\n",
        "\n",
        "# ECG 신호의 어노테이션(annotation)을 5단계로 축소\n",
        "def aami_class(sym): # sym :MIT-BIH beat, cls : AAMI_5단계 분류\n",
        "    for cls, syms in AAMI_MAP.items():\n",
        "        if sym in syms: return cls\n",
        "    return None\n",
        "\n",
        "# aami_class의 5단계 구조 ->이진 분류\n",
        "def bin_label_from_aami(aami_cls): # aami_cls: aami_class에서 나온결과(5가지 중 1개)\n",
        "    if aami_cls == 'N': return 0  # 정상\n",
        "    if aami_cls in ('S','V','F'): return 1  # 부정맥\n",
        "    return None  # Q 등 제외\n"
      ],
      "metadata": {
        "id": "je2xYq41o_Fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이진 라벨 부여"
      ],
      "metadata": {
        "id": "BbfdfzsuS_2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#레코드당 어노테이션(의사(전문가)가 붙인 이벤트 정보) 읽고 이진 라벨 부여\n",
        "def load_record_beats(rec_id:str):\n",
        "    ann = wfdb.rdann(str(BASE/rec_id), 'atr')\n",
        "    df = pd.DataFrame({'sample': ann.sample, 'symbol': ann.symbol}) # sample,symbol열 추가\n",
        "\n",
        "    # 제외( paced/논비트/분류불가 ) 제거\n",
        "    df = df[~df['symbol'].isin(EXCLUDE)].copy()\n",
        "\n",
        "    # AAMI 클래스 찾기(모르는 심볼은 버림)\n",
        "    df['aami'] = df['symbol'].apply(aami_class) #aami열 추가\n",
        "    df = df[df['aami'].notnull()].copy()\n",
        "\n",
        "    # 이진 라벨\n",
        "    df['label'] = df['aami'].apply(bin_label_from_aami) #label열 추가\n",
        "    df = df[df['label'].notnull()].copy()\n",
        "    df['rec_id'] = rec_id # rec_id열 추가\n",
        "\n",
        "    return df.reset_index(drop=True) # 행 인덱스를 0-N-1로 리셋해서 깔끔하게 반환\n"
      ],
      "metadata": {
        "id": "fvPHe-rtpAPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예시\n",
        "print(load_record_beats('100'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7j94Xfzfzo5",
        "outputId": "c4056594-0f8d-408f-e3fb-4798d522db4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      sample symbol aami  label rec_id\n",
            "0         77      N    N      0    100\n",
            "1        370      N    N      0    100\n",
            "2        662      N    N      0    100\n",
            "3        946      N    N      0    100\n",
            "4       1231      N    N      0    100\n",
            "...      ...    ...  ...    ...    ...\n",
            "2268  648978      N    N      0    100\n",
            "2269  649232      N    N      0    100\n",
            "2270  649484      N    N      0    100\n",
            "2271  649734      N    N      0    100\n",
            "2272  649991      N    N      0    100\n",
            "\n",
            "[2273 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습/검증/테스트 데이터 별로 나눠서 합치기\n",
        "def build_split(recs): # recs : 레코드 ID들의 리스트\n",
        "    parts = []\n",
        "    for rec_id in recs:\n",
        "        try:\n",
        "            parts.append(load_record_beats(rec_id)) # 이진분류 결과를 저장\n",
        "        except Exception as e:\n",
        "            print(f'[WARN] {rec_id}: {e}')\n",
        "    return pd.concat(parts, ignore_index=True) if parts else pd.DataFrame()"
      ],
      "metadata": {
        "id": "_bCzAeDZpCIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(build_split(test_recs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c16KKaJvrT5i",
        "outputId": "483916d3-d4b8-4289-e27e-d060ccb52825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       sample symbol aami  label rec_id\n",
            "0          77      N    N      0    100\n",
            "1         370      N    N      0    100\n",
            "2         662      N    N      0    100\n",
            "3         946      N    N      0    100\n",
            "4        1231      N    N      0    100\n",
            "...       ...    ...  ...    ...    ...\n",
            "49700  648797      N    N      0    234\n",
            "49701  649040      N    N      0    234\n",
            "49702  649292      N    N      0    234\n",
            "49703  649536      N    N      0    234\n",
            "49704  649772      N    N      0    234\n",
            "\n",
            "[49705 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = build_split(train_recs)\n",
        "val_df = build_split(val_recs)\n",
        "test_df = build_split(test_recs)\n",
        "\n",
        "#학습을 위한 라벨 생성\n",
        "train_labels = train_df['label'].to_numpy()\n",
        "val_labels = val_df['label'].to_numpy()\n",
        "test_labels = test_df['label'].to_numpy()\n",
        "\n",
        "print('\\n\\n======================train_labels 측정====================')\n",
        "print(train_labels)\n",
        "print('\\n\\n======================val_labels 측정======================')\n",
        "print(val_labels)\n",
        "print('\\n\\n======================test_labels 측정====================')\n",
        "print(test_labels)\n",
        "\n",
        "for name, df in [('train', train_df), ('val', val_df), ('test', test_df)]: #train,val,test반복\n",
        "    total = len(df)\n",
        "    pos = int(df['label'].sum()) #label 컬럼의 합 (정상=0, 부정맥=1이라고 가정하니까, 합계를 구하면 곧 부정맥 개수)\n",
        "    neg = total - pos # 전체 개수에서 부정맥 개수를 빼면 정상 개수\n",
        "    print(f'{name:5s} -> total {total:6d} | 정상(0): {neg:6d} | 부정맥(1): {pos:6d}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef5UoFa52PXq",
        "outputId": "70037d01-9ffb-4b16-e2c4-53c4b847bbe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "======================train_labels 측정====================\n",
            "[0 0 0 ... 0 0 0]\n",
            "\n",
            "\n",
            "======================val_labels 측정======================\n",
            "[0 0 0 ... 0 0 0]\n",
            "\n",
            "\n",
            "======================test_labels 측정====================\n",
            "[0 0 0 ... 0 0 0]\n",
            "train -> total  40741 | 정상(0):  36417 | 부정맥(1):   4324\n",
            "val   -> total  10272 | 정상(0):   9449 | 부정맥(1):    823\n",
            "test  -> total  49705 | 정상(0):  44259 | 부정맥(1):   5446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 차후 학습 샘플링을 위한 samples 정리\n",
        "train_samples = {}\n",
        "val_samples = {}\n",
        "test_samples = {}\n",
        "\n",
        "for rec_id in train_df['rec_id'].unique():\n",
        "  train_samples[rec_id] = train_df[train_df['rec_id'] == rec_id]['sample'].to_numpy()\n",
        "\n",
        "for rec_id in val_df['rec_id'].unique():\n",
        "  val_samples[rec_id] = val_df[val_df['rec_id'] == rec_id]['sample'].to_numpy()\n",
        "\n",
        "for rec_id in test_df['rec_id'].unique():\n",
        "  test_samples[rec_id] = test_df[test_df['rec_id'] == rec_id]['sample'].to_numpy()\n",
        "\n",
        "print('\\n\\n======================train_samples 측정====================')\n",
        "print(train_samples)\n",
        "print('\\n\\n======================val_samples 측정======================')\n",
        "print(val_samples)\n",
        "print('\\n\\n======================test_samples 측정====================')\n",
        "print(test_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtrRUz10REqf",
        "outputId": "a30e3b46-f7c8-473d-fb90-fb33b8d4e2de",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "======================train_samples 측정====================\n",
            "{'101': array([    83,    396,    711, ..., 649004, 649372, 649751]), '106': array([   351,    724,   1086, ..., 649162, 649340, 649791]), '108': array([    88,    442,    789, ..., 649170, 649471, 649769]), '109': array([   111,    343,    571, ..., 649378, 649663, 649931]), '112': array([   124,    382,    644, ..., 649361, 649626, 649883]), '114': array([   310,    726,   1143, ..., 649261, 649523, 649783]), '115': array([   161,    518,    850, ..., 649357, 649647, 649955]), '116': array([   282,    561,    837, ..., 649442, 649701, 649957]), '118': array([    68,    369,    674, ..., 649226, 649429, 649742]), '119': array([   309,    503,    977, ..., 649129, 649468, 649788]), '122': array([    93,    326,    561, ..., 649383, 649643, 649905]), '124': array([   243,    693,   1119, ..., 649146, 649510, 649876]), '201': array([   159,    415,    686, ..., 648594, 649104, 649800]), '203': array([    99,    431,    660, ..., 649237, 649448, 649777]), '205': array([   229,    466,    706, ..., 649326, 649596, 649857]), '207': array([    50,    312,    835, ..., 649431, 649602, 649799]), '208': array([    46,    209,    483, ..., 649411, 649704, 649935]), '209': array([   189,    425,    659, ..., 649387, 649627, 649857])}\n",
            "\n",
            "\n",
            "======================val_samples 측정======================\n",
            "{'215': array([   124,    313,    503, ..., 649501, 649685, 649875]), '220': array([    28,    313,    612, ..., 649277, 649584, 649904]), '223': array([   204,    480,    759, ..., 649349, 649599, 649849]), '230': array([    75,    349,    616, ..., 649338, 649572, 649807])}\n",
            "\n",
            "\n",
            "======================test_samples 측정====================\n",
            "{'100': array([    77,    370,    662, ..., 649484, 649734, 649991]), '103': array([   265,    575,    876, ..., 649195, 649534, 649875]), '105': array([   197,    459,    708, ..., 649221, 649471, 649740]), '111': array([   197,    489,    804, ..., 649148, 649441, 649724]), '113': array([   170,    583,    966, ..., 649364, 649675, 649994]), '117': array([   189,    598,   1006, ..., 649070, 649498, 649926]), '121': array([   163,    513,    874, ..., 649287, 649587, 649878]), '123': array([    70,    550,   1021, ..., 648997, 649342, 649689]), '200': array([   225,    487,    689, ..., 649408, 649664, 649927]), '202': array([   348,    742,   1155, ..., 649342, 649615, 649877]), '210': array([    57,    250,    471, ..., 649513, 649758, 649962]), '212': array([   214,    451,    696, ..., 649414, 649673, 649945]), '213': array([    95,    253,    478, ..., 649577, 649790, 649992]), '214': array([    58,    346,    660, ..., 649379, 649627, 649891]), '219': array([   300,    614,    887, ..., 649174, 649448, 649737]), '221': array([   220,    442,    603, ..., 649236, 649530, 649810]), '222': array([    81,    361,    646, ..., 649317, 649600, 649859]), '228': array([   160,    433,    726, ..., 649108, 649332, 649761]), '231': array([   180,    527,    847, ..., 649142, 649501, 649862]), '232': array([   491,    737,   1000, ..., 648845, 649097, 649366]), '233': array([    42,    320,    511, ..., 649518, 649730, 649946]), '234': array([   135,    366,    606, ..., 649292, 649536, 649772])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "OTLSFQ_cy6pC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1 HPF 제거 & Baseline 제거 & 슬라이싱 & 정규화\n",
        "\n",
        "fc = 0.5 Hz\n",
        "\n",
        "MIT-BIH는 보통 fs=360 Hz이므로\n",
        "\n",
        "wn = fc / (fs/2) 로 정규화\n",
        "\n",
        "하이패스 필터(HPF) 적용\n",
        "\n",
        "Butterworth 하이패스 필터를 적용"
      ],
      "metadata": {
        "id": "VDcQyGQcWheW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def highpass_filter(data, order=5): #data는 np.ndarray형식\n",
        "    nyquist = 0.5 * FS\n",
        "    normal_cutoff = CUTOFF / nyquist\n",
        "    b, a = butter(order, normal_cutoff, btype='high', analog=False) # order은 필터 차수\n",
        "    # 위상왜곡 제거(오프라인 전처리)\n",
        "    filtered_data = lfilter(b, a, data) #IIR/FIR 필터를 선형 차분 방정식(디지털 필터식)에 따라 적용\n",
        "    return filtered_data"
      ],
      "metadata": {
        "id": "lx3JwrrtW1Pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class ECGDataset(Dataset):\n",
        "    def __init__(self, df, base_path=BASE, window_size=WINDOW_SIZE):\n",
        "        self.entries = df[['rec_id','sample','label']].to_records(index=False)\n",
        "        self.base = base_path\n",
        "        self.window_size = window_size\n",
        "        self.half = window_size // 2\n",
        "        self.signal_caches = {}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.entries)\n",
        "\n",
        "    def _get_signal(self, rec_id): #hpf 제거 & HPF 적용\n",
        "        if rec_id not in self.signal_caches:\n",
        "            record = wfdb.rdrecord(str(self.base / rec_id))\n",
        "            sig = record.p_signal[:,0]\n",
        "            self.signal_caches[rec_id] = highpass_filter(sig)\n",
        "        return self.signal_caches[rec_id]\n",
        "\n",
        "    def __getitem__(self, idx): # r_pick기준으로 슬라이싱\n",
        "        rec_id, sample, label = self.entries[idx]\n",
        "        sig = self._get_signal(rec_id)\n",
        "\n",
        "        start = int(sample - self.half)\n",
        "        end   = int(sample + self.half + 1)\n",
        "\n",
        "        if start < 0 or end > sig.shape[0]: # seg 길이가 361이 되지 않으면 패딩\n",
        "            seg = np.zeros(self.window_size, dtype=np.float32)\n",
        "        else:\n",
        "            seg = sig[start:end].astype(np.float32) # 슬라이싱 윈도우\n",
        "            mean, std = seg.mean(), seg.std()# 정규화\n",
        "            seg = np.zeros_like(seg) if std==0 else (seg-mean)/std\n",
        "\n",
        "        return torch.from_numpy(seg).float(), torch.tensor(int(label)).long()"
      ],
      "metadata": {
        "id": "qMTkRM5YN_JC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.4 AI 모델 학습\n",
        "\n",
        "Features:\n",
        "- On-the-fly Dataset that caches per-record filtered signal (HPF)\n",
        "- CNN-LSTM model (conv->pool->conv->pool->LSTM->FC)\n",
        "- Weighted CrossEntropyLoss to handle class imbalance\n",
        "- Optional WeightedRandomSampler alternative (commented)\n",
        "- Training loop with validation, scheduler, early stopping, and metrics (precision/recall/f1)\n",
        "- Model saving (best val F1)"
      ],
      "metadata": {
        "id": "ou9SL8Do3kQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
        "\n",
        "HYP = {\n",
        "    'window_size': 361,\n",
        "    'batch_size': 64,\n",
        "    'num_epochs': 60,\n",
        "    'lr': 1e-3,\n",
        "    'weight_decay': 1e-5,\n",
        "    'conv_channels': [32, 64],\n",
        "    'kernel_size': 5,\n",
        "    'lstm_hidden': 64,\n",
        "    'lstm_layers': 1,\n",
        "    'bidirectional': False,\n",
        "    'dropout': 0.3,\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    'patience': 8,  # early stopping patience (epochs)\n",
        "}"
      ],
      "metadata": {
        "id": "xHjXKu1-fxGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNNLSTM_ECG — 1D conv 2층 → 풀링 → 시퀀스 차원으로 변환 → LSTM → FC"
      ],
      "metadata": {
        "id": "q4F6-3lT_fF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- Model (CNN -> LSTM) --------------------------------\n",
        "class CNNLSTM_ECG(nn.Module):\n",
        "    '''\n",
        "    in_channels: 입력 채널 수\n",
        "    n_classes: 최종 분류할 라벨 수\n",
        "    conv_channels:CNN계층에서 사용할 필터 개수([32,64]-> 첫번째 합성곱은 32개의 특징맵 생성)\n",
        "    kernel_size: CNN 커널 길이.인접한 n개의 시점 정보를 활용해서 특징을 잡음 (작으면 세밀한 특징, 크면 넓은 패턴을 잘잡음)\n",
        "    lstm_hidden: 한 시점에서 기억하는 특징의 차원 수\n",
        "    lstm_layers:LSTM 층 개수\n",
        "    bidirectional:LSTM을 양방향으로 쓸지 여부(False:과거->현재 일방향)\n",
        "    dropout: 뉴런 일부를 학습 중 무작위로 꺼서 과적합을 방지하는 비율\n",
        "    '''\n",
        "\n",
        "    def __init__(self, in_channels=1, n_classes=2, conv_channels=[32,64], kernel_size=5,\n",
        "                 lstm_hidden=64, lstm_layers=1, bidirectional=False, dropout=0.3):\n",
        "        super().__init__()\n",
        "        padding = kernel_size // 2\n",
        "        self.conv1 = nn.Conv1d(in_channels, conv_channels[0], kernel_size, padding=padding)\n",
        "        self.bn1 = nn.BatchNorm1d(conv_channels[0])\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(conv_channels[0], conv_channels[1], kernel_size, padding=padding)\n",
        "        self.bn2 = nn.BatchNorm1d(conv_channels[1]) # 1원데이터 배치 정규화\n",
        "        self.pool2 = nn.MaxPool1d(2) # 1차원입력 최댓값 풀링\n",
        "\n",
        "        self.relu = nn.ReLU() # 비선형 활성화\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.bidirectional = bidirectional\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size = conv_channels[1],\n",
        "            hidden_size = lstm_hidden,\n",
        "            num_layers = lstm_layers,\n",
        "            batch_first = True,\n",
        "            bidirectional = bidirectional,\n",
        "            dropout = dropout if lstm_layers>1 else 0.0\n",
        "        )\n",
        "\n",
        "        lstm_out_dim = lstm_hidden * (2 if bidirectional else 1)\n",
        "        self.fc = nn.Linear(lstm_out_dim, n_classes) # 입력에대해 y - xw^T + b 변환을 수행하는 FC\n",
        "    def forward(self, x):\n",
        "        # Input x: (batch, channel=1, length)\n",
        "        x = self.pool1(self.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool2(self.relu(self.bn2(self.conv2(x))))\n",
        "\n",
        "        # x: (batch, channels=conv_channels[1], seq_len_reduced)\n",
        "        x = x.permute(0, 2, 1)  # -> (batch, seq_len, feature)\n",
        "        out, (h_n, c_n) = self.lstm(x)\n",
        "        # take last hidden state\n",
        "        if self.bidirectional:\n",
        "            h = torch.cat([h_n[-2], h_n[-1]], dim=1)\n",
        "        else:\n",
        "            h = h_n[-1]\n",
        "        h = self.dropout(h)\n",
        "        return self.fc(h)"
      ],
      "metadata": {
        "id": "SuL_-4zGgHU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- Utilities -------------------------------------------\n",
        "def compute_class_weights_from_df(df):\n",
        "    labels = df['label'].to_numpy()\n",
        "    counts = Counter(labels)\n",
        "    # weight = total / (num_classes * count) typical\n",
        "    num_classes = len(counts)\n",
        "    total = sum(counts.values())\n",
        "    weights = []\n",
        "    for cls in range(num_classes):\n",
        "        weights.append(total / (num_classes * (counts.get(cls,0) + 1e-6)))\n",
        "    return torch.tensor(weights, dtype=torch.float32)\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # batch: list of tuples (segment_tensor (L,), label)\n",
        "    xs = torch.stack([b[0] for b in batch], dim=0)  # (B, L)\n",
        "    xs = xs.unsqueeze(1)  # (B, 1, L)\n",
        "    ys = torch.tensor([int(b[1]) for b in batch], dtype=torch.long)\n",
        "    return xs, ys"
      ],
      "metadata": {
        "id": "D9FxYQmFgdgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- Training / Evaluation loops -------------------------\n",
        "def evaluate(model, dataloader, device):\n",
        "    model.eval()\n",
        "    ys_all = []\n",
        "    ps_all = []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in dataloader:\n",
        "            xb = xb.to(device)\n",
        "            yb = yb.to(device)\n",
        "            logits = model(xb)\n",
        "            probs = torch.softmax(logits, dim=1)[:,1].detach().cpu().numpy()  # positive probs\n",
        "            preds = logits.argmax(dim=1).detach().cpu().numpy()\n",
        "            ys_all.extend(yb.detach().cpu().numpy().tolist())\n",
        "            ps_all.extend(preds.tolist())\n",
        "    p, r, f1, _ = precision_recall_fscore_support(ys_all, ps_all, average='binary', zero_division=0)\n",
        "    # roc auc (if both classes present)\n",
        "    try:\n",
        "        auc = roc_auc_score(ys_all, np.array(ps_all))\n",
        "    except Exception:\n",
        "        auc = float('nan')\n",
        "    return {'precision':p, 'recall':r, 'f1':f1, 'auc':auc}"
      ],
      "metadata": {
        "id": "LgK_d6f4gmz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_full(train_df, val_df, test_df, base_path, hyp=HYP, save_path='./best_model.pth'):\n",
        "    device = torch.device(hyp['device'])\n",
        "\n",
        "    # Datasets\n",
        "    train_ds = ECGDataset(train_df, base_path, window_size=hyp['window_size'])\n",
        "    val_ds   = ECGDataset(val_df,   base_path, window_size=hyp['window_size'])\n",
        "    test_ds  = ECGDataset(test_df,  base_path, window_size=hyp['window_size'])\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=hyp['batch_size'], shuffle=True, collate_fn=collate_fn, num_workers=2)\n",
        "    val_loader   = DataLoader(val_ds,   batch_size=hyp['batch_size'], shuffle=False, collate_fn=collate_fn, num_workers=2)\n",
        "    test_loader  = DataLoader(test_ds,  batch_size=hyp['batch_size'], shuffle=False, collate_fn=collate_fn, num_workers=2)\n",
        "\n",
        "    model = CNNLSTM_ECG(\n",
        "        in_channels=1,\n",
        "        n_classes=2,\n",
        "        conv_channels=hyp['conv_channels'],\n",
        "        kernel_size=hyp['kernel_size'],\n",
        "        lstm_hidden=hyp['lstm_hidden'],\n",
        "        lstm_layers=hyp['lstm_layers'],\n",
        "        bidirectional=hyp['bidirectional'],\n",
        "        dropout=hyp['dropout']\n",
        "    ).to(device)\n",
        "\n",
        "    # Loss with class weights\n",
        "    class_weights = compute_class_weights_from_df(train_df).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=hyp['lr'], weight_decay=hyp['weight_decay'])\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
        "\n",
        "    best_val_f1 = -1.0\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, hyp['num_epochs']+1):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        n_samples = 0\n",
        "        t0 = time.time()\n",
        "        for xb, yb in train_loader:\n",
        "            xb = xb.to(device)\n",
        "            yb = yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item() * xb.size(0)\n",
        "            n_samples += xb.size(0)\n",
        "        epoch_loss /= max(1, n_samples)\n",
        "\n",
        "        val_metrics = evaluate(model, val_loader, device)\n",
        "        print(f\"Epoch {epoch:03d} | train_loss: {epoch_loss:.4f} | val_f1: {val_metrics['f1']:.4f} | val_prec: {val_metrics['precision']:.4f} | val_rec: {val_metrics['recall']:.4f} | time: {time.time()-t0:.1f}s\")\n",
        "\n",
        "        # scheduler on val loss proxy (use 1 - f1 as loss) or use epoch_loss\n",
        "        scheduler.step(1.0 - val_metrics['f1'])\n",
        "\n",
        "        # early stopping logic\n",
        "        if val_metrics['f1'] > best_val_f1:\n",
        "            best_val_f1 = val_metrics['f1']\n",
        "            epochs_no_improve = 0\n",
        "            torch.save({'model_state': model.state_dict(), 'hyp': hyp}, save_path)\n",
        "            print(f\"  -> new best model saved (val_f1 {best_val_f1:.4f})\")\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= hyp['patience']:\n",
        "                print(f\"Early stopping (no improvement for {hyp['patience']} epochs). Best val_f1={best_val_f1:.4f}\")\n",
        "                break\n",
        "\n",
        "    # load best\n",
        "    ckpt = torch.load(save_path, map_location=device)\n",
        "    model.load_state_dict(ckpt['model_state'])\n",
        "    test_metrics = evaluate(model, test_loader, device)\n",
        "    print(\"Test metrics:\", test_metrics)\n",
        "    return model, best_val_f1, test_metrics\n"
      ],
      "metadata": {
        "id": "XcVgr0YYfaex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- Example entrypoint ---------------------------------\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        model, best_f1, test_metrics = train_full(train_df, val_df, test_df, BASE)\n",
        "    except Exception as e:\n",
        "        print(\"Error running training:\", e)\n",
        "        raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YiIGX5A51f3",
        "outputId": "96e0e645-5ab2-4087-ac03-e532e122f736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001 | train_loss: 0.3982 | val_f1: 0.1878 | val_prec: 0.1132 | val_rec: 0.5504 | time: 9.7s\n",
            "  -> new best model saved (val_f1 0.1878)\n",
            "Epoch 002 | train_loss: 0.2255 | val_f1: 0.2722 | val_prec: 0.1671 | val_rec: 0.7339 | time: 8.7s\n",
            "  -> new best model saved (val_f1 0.2722)\n",
            "Epoch 003 | train_loss: 0.1870 | val_f1: 0.4343 | val_prec: 0.2952 | val_rec: 0.8214 | time: 8.5s\n",
            "  -> new best model saved (val_f1 0.4343)\n",
            "Epoch 004 | train_loss: 0.1700 | val_f1: 0.4553 | val_prec: 0.3156 | val_rec: 0.8165 | time: 12.9s\n",
            "  -> new best model saved (val_f1 0.4553)\n",
            "Epoch 005 | train_loss: 0.1360 | val_f1: 0.3313 | val_prec: 0.2133 | val_rec: 0.7424 | time: 13.2s\n",
            "Epoch 006 | train_loss: 0.1207 | val_f1: 0.4921 | val_prec: 0.3564 | val_rec: 0.7947 | time: 7.8s\n",
            "  -> new best model saved (val_f1 0.4921)\n",
            "Epoch 007 | train_loss: 0.1178 | val_f1: 0.4139 | val_prec: 0.2786 | val_rec: 0.8044 | time: 8.6s\n",
            "Epoch 008 | train_loss: 0.1170 | val_f1: 0.2855 | val_prec: 0.1706 | val_rec: 0.8736 | time: 8.5s\n",
            "Epoch 009 | train_loss: 0.1050 | val_f1: 0.3443 | val_prec: 0.2164 | val_rec: 0.8420 | time: 7.7s\n",
            "Epoch 010 | train_loss: 0.1065 | val_f1: 0.3423 | val_prec: 0.2262 | val_rec: 0.7035 | time: 8.8s\n",
            "Epoch 011 | train_loss: 0.0863 | val_f1: 0.2437 | val_prec: 0.1479 | val_rec: 0.6926 | time: 8.6s\n",
            "Epoch 012 | train_loss: 0.0694 | val_f1: 0.3018 | val_prec: 0.1869 | val_rec: 0.7825 | time: 7.8s\n",
            "Epoch 013 | train_loss: 0.0618 | val_f1: 0.2462 | val_prec: 0.1472 | val_rec: 0.7521 | time: 8.6s\n",
            "Epoch 014 | train_loss: 0.0677 | val_f1: 0.2343 | val_prec: 0.1420 | val_rec: 0.6695 | time: 8.8s\n",
            "Early stopping (no improvement for 8 epochs). Best val_f1=0.4921\n",
            "Test metrics: {'precision': 0.3508810331618693, 'recall': 0.5886889460154242, 'f1': 0.43969005005828704, 'auc': np.float64(0.7273411516493443)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "93I0K1sT9FXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.5 TFLite로 내보내기 & 양자화"
      ],
      "metadata": {
        "id": "WKcbD38G3o9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# TFLite 컨버터를 생성\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# 양자화 옵션을 설정\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# TFLite 모델로 변환\n",
        "ECG_tflite_model = converter.convert()\n",
        "\n",
        "# 변환된 모델을 파일로 저장\n",
        "with open('my_model.tflite', 'wb') as f:\n",
        "    f.write(ECG_tflite_model)"
      ],
      "metadata": {
        "id": "sc1mDgCBaID4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "e9cb498f-1183-43b7-9f00-2cc077f2e3d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'CNNLSTM_ECG' object has no attribute 'call'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2221909915.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# TFLite 모델로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mECG_tflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 변환된 모델을 파일로 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1248\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_and_export_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1200\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_conversion_params_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1203\u001b[0m     \u001b[0melapsed_time_ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m     graph_def, input_tensors, output_tensors, frozen_func = (\n\u001b[0;32m-> 1773\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_freeze_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m     )\n\u001b[1;32m   1775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mreport_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Re-throws the exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mConverterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_freeze_keras_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1708\u001b[0m     \u001b[0;31m# to None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m     \u001b[0;31m# Once we have better support for dynamic shapes, we can remove this.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1710\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_def_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m       \u001b[0;31m# Pass `keep_original_batch_size=True` will ensure that we get an input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m       \u001b[0;31m# signature including the batch dimension specified by the user.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1960\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1961\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1962\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1963\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'CNNLSTM_ECG' object has no attribute 'call'"
          ]
        }
      ]
    }
  ]
}